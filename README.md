# bfm-robust
Companion repo for robustness specification in biomedical foundation models (BFMs)

### Surveys \& tutorials
* [A.I. Robustness: a Human-Centered Perspective on Technological Challenges and Opportunities](https://dl.acm.org/doi/10.1145/3665926), *ACM Comput. Surv.* (2024)
* [Machine Learning Robustness: A Primer](https://arxiv.org/abs/2404.00897), arXiv:2404.00897
* [Foundational Robustness of Foundation Models](https://sites.google.com/view/neurips2022-frfm-turotial/home), NeurIPS Tutorial (2022)

### Group robustness
* [Prompting is a Double-Edged Sword: Improving Worst-Group Robustness of Foundation Models](https://proceedings.mlr.press/v235/setlur24a.html), ICML (2024)
* [Improving Group Robustness on Spurious Correlation Requires Preciser Group Inference](https://proceedings.mlr.press/v235/han24g.html), ICML (2024)
* [Controllable Prompt Tuning For Balancing Group Distributional Robustness](https://proceedings.mlr.press/v235/phan24b.html), ICML (2024)
* [Multigroup Robustness](https://proceedings.mlr.press/v235/hu24l.html), ICML (2024)
* [Change is hard: a closer look at subpopulation shift](https://proceedings.mlr.press/v202/yang23s.html), ICML (2023)
* [Just Train Twice: Improving Group Robustness without Training Group Information](https://proceedings.mlr.press/v139/liu21f.html), ICML (2021)
* [No Subclass Left Behind: Fine-Grained Robustness in Coarse-Grained Classification Problems](https://proceedings.neurips.cc/paper/2020/hash/e0688d13958a19e087e123148555e4b4-Abstract.html), NeurIPS (2020)

### Instance-wise robustness
* [Characterizing Data Point Vulnerability as Average-Case Robustness](https://proceedings.mlr.press/v244/han24a.html), UAI (2024)
* [Characterizing the Impacts of Instances on Robustness](https://aclanthology.org/2023.findings-acl.146/), ACL (2023)

### Uncertainty awareness \& Uncertainty-aware robustness
* [Domain-specific or Uncertainty-aware models: Does it really make a difference for biomedical text classification?](https://aclanthology.org/2024.bionlp-1.16/), ACL BioNLP Workshop (2024)
* [Certainly Uncertain: A Benchmark and Metric for Multimodal Epistemic and Aleatoric Awareness](https://arxiv.org/abs/2407.01942), arXiv:2407.01942
* [Uncertainty-Aware Pre-Trained Foundation Models for Patient Risk Prediction via Gaussian Process](https://dl.acm.org/doi/10.1145/3589335.3651456), WWW (2024)

### Longitudinal/Temporal robustness
* [Pathophysiological Features in Electronic Medical Records Sustain Model Performance under Temporal Dataset Shift](https://pmc.ncbi.nlm.nih.gov/articles/PMC11141811/), AMIA (2024)
* [Stable clinical risk prediction against distribution shift in electronic health records](https://www.cell.com/patterns/fulltext/S2666-3899(23)00197-6), *Patterns* (2023)
* [EHR foundation models improve robustness in the presence of temporal distribution shift](https://www.nature.com/articles/s41598-023-30820-8), *Sci. Rep.* (2023)
* [Evaluation of domain generalization and adaptation on improving model robustness to temporal dataset shift in clinical medicine](https://www.nature.com/articles/s41598-022-06484-1), *Sci. Rep.* (2022)

### Knowledge robustness
* [Medical large language models are susceptible to targeted misinformation attacks](https://www.nature.com/articles/s41746-024-01282-7), *npj Digit. Med.* (2024)
* [PromptSmooth: Certifying Robustness of Medical Vision-Language Models via Prompt Learning](https://link.springer.com/chapter/10.1007/978-3-031-72390-2_65), MICCAI (2024)
* [Large Diverse Ensembles for Robust Clinical NLI](https://aclanthology.org/2024.semeval-1.224/), SemEval (2024)
* [MedFuzz: Exploring the Robustness of Large Language Models in Medical Question Answering](https://arxiv.org/abs/2406.06573), arXiv:2406.06573
* [Adversarial Attacks on Large Language Models in Medicine](https://arxiv.org/abs/2406.12259), arXiv:2406.12259
* [Poisoning medical knowledge using large language models](https://www.nature.com/articles/s42256-024-00899-3), *Nat. Mach. Intell.* (2024)
* [Backdoor Attack on Unpaired Medical Image-Text Foundation Models: A Pilot Study on MedCLIP](https://ieeexplore.ieee.org/document/10516621), SaTML (2024)
* [Assessing biomedical knowledge robustness in large language models by query-efficient sampling attacks](https://arxiv.org/abs/2402.10527), arXiv:2402.10527
* [Demonstration of an Adversarial Attack Against a Multimodal Vision Language Model for Pathology Imaging](https://arxiv.org/abs/2401.02565), arXiv:2401.02565
* [Robust and data-efficient generalization of self-supervised machine learning for diagnostic imaging](https://www.nature.com/articles/s41551-023-01049-7), *Nat. Biomed. Eng.* (2023)

### Pref-BFM adversarial robustness (language)
* [Evaluating the Robustness of Adverse Drug Event Classification Models using Templates](https://aclanthology.org/2024.bionlp-1.3/), ACL BioNLP Workshop (2024)
* [Incorporating Data Augmentation with Generative Models and Biomedical Knowledge to Enhance Inference Robustness](https://aclanthology.org/2024.semeval-1.15/), SemEval (2024)
* [Enhancing Robustness of Foundation Model Representations under Provenance-related Distribution Shifts](https://openreview.net/forum?id=9TVx8T0U1h), NeurIPS DistShift Workshop (2023)
* [Evaluating the Robustness of Biomedical Concept Normalization](https://proceedings.mlr.press/v203/chakraborty23a.html), NeurIPS TLNLP Workshop (2022)
* [Improving the robustness and accuracy of biomedical language models through adversarial training](https://www.sciencedirect.com/science/article/pii/S1532046422001307), *J. Biomed. Inform.* (2022)

### Pref-BFM adversarial robustness (vision)
* [Adversarial attacks in radiology â€“ A systematic review](https://www.ejradiology.com/article/S0720-048X(23)00399-6/fulltext), *Eur. J. Radiol.* (2023)
* [Adversarial attacks and adversarial robustness in computational pathology](https://www.nature.com/articles/s41467-022-33266-0), *Nat. Comm.* (2022)
* [Advancing diagnostic performance and clinical usability of neural networks via adversarial training and dual batch normalization](https://www.nature.com/articles/s41467-021-24464-3), *Nat. Comm.* (2021)
* [Adversarial attacks on medical machine learning](https://www.science.org/doi/10.1126/science.aaw4399), *Science* (2019)

### Robustness evaluation
* [The Data Addition Dilemma](https://arxiv.org/abs/2408.04154), arXiv:2408.04154
* [Evaluating Robustness to Dataset Shift via Parametric Robustness Sets](https://proceedings.neurips.cc/paper_files/paper/2022/hash/6b7f9d9c1217a748391800871ff7d17d-Abstract-Conference.html), NeurIPS (2022)
* [A Fine-Grained Analysis on Distribution Shift](https://openreview.net/forum?id=Dl4LetuLdyK), ICLR (2022)
* [Mandoline: Model Evaluation under Distribution Shift](https://proceedings.mlr.press/v139/chen21i.html), ICML (2021)